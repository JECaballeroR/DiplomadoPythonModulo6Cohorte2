{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ppscore as pps\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Employee turnover: Predecir la probabilidad de que un empleado renuncie usando Machine Learning\n",
    "### ¿Cómo podemos retener nuestro talento?\n",
    "\n",
    "Es una pregunta que toda organización del mundo debería hacerse.\n",
    "El talento es el insumo de mayor valor para cada organización,\n",
    "dado que es el mayor generador de valor:\n",
    "No importan los recursos si no hay gente habilidosa, motivada detrás de ellos.\n",
    "\n",
    "Para poder retener el talento, es necesario entender\n",
    "la razón de la salida de los empleados: si se sabe quién está en riesgo\n",
    " de abandonar la organización, se pueden tomar medidas preventivas.\n",
    "\n",
    "En el presente Jupyter notebook, se ilustrará el proceso\n",
    "para la obtención de un modelo preliminar de\n",
    "Machine Learning para la predicción de la probabilidad de que\n",
    "un empleado abandone una organización. Para esto,\n",
    "se utilizará un dataset de Kaggle que contiene una serie\n",
    " de features asociadas a los empleados, además de\n",
    " una variable binaria que determina si el empleado abandonó o no la organización.\n",
    "\n",
    "A grandes rasgos, los pasos que se seguirán serán:\n",
    "\n",
    "* **Carga y validación de los datos**:\n",
    " Se verifica que los datos a usar sean integrales, que no haya faltantes, que sus valores sean coherentes con la realidad.\n",
    "* **Análisis Exploratorio**:\n",
    "Se exploran los datos para detectar posibles interacciones de interés. En el caso de dataset con muchos features, se usaría como base para empezar con los modelos.\n",
    "* **Preparación de los datos**:\n",
    " Se realiza preparación y limpieza de datos para los modelos (Normalizar, Estandarizar, Upsampling/Downsampling, generación de datos sintéticos, rellenado de faltantes, entre otras posibilidades). Adicionalmente, se separa un fragmento de los datos para posteriormente probar los modelos en ellos.\n",
    "* **Modelado inicial**:\n",
    "Se prueba con algunos modelos básicos.\n",
    "* **Optimización de hiper parámetros**:\n",
    "Se aproxima a la mejor combinación de hiper parámetros del modelo seleccionado para los datos que se tienen.\n",
    "* **Selección del mejor modelo**:\n",
    " Con los datos separados en el punto 3, se prueban todos los modelos y se elige aquel con un mejor desempeño.\n",
    "\n",
    "\n",
    "## Carga y exploración básica\n",
    "\n",
    "Los features del dataset son:\n",
    "\n",
    "- **satisfaction_level**: Nivel de Satisfacción, de 0 a 1 (Flotante).\n",
    "- **last_evaluation**: Años desde la última evaluación de desempeño (Flotante)\n",
    "- **number_project**: Cantidad de proyectos terminados durante la vinculación laboral (Entera)\n",
    "- **average_montly_hours**: Horas promedio mensuales trabajadas (Entera)\n",
    "- **time_spend_company**: Años de vinculación en la compañía (Entera)\n",
    "- **Work_accident**: Si el empleado tuvo o no Accidente de trabajo (Binaria)\n",
    "- **left**: Si el empleado dejo o no el trabajo (Variable Respuesta) (Binaria)\n",
    "- **promotion_last_5years**: Si el empleado tuvo o no un ascenso en los últimos 5 años (Binaria).\n",
    "- **sales**: Departamento al que el empleado estuvo vinculado (Categórica).\n",
    "- **salary**: Nivel relativo del salario (low, medium, high) (Categórica)\n",
    "\n",
    "Se cargan los datos y se validan ciertos elementos, a saber:\n",
    "\n",
    "* Que no haya datos faltantes\n",
    "* Que todos los datos sean coherentes con las variables\n",
    "* Que la variable respuesta esté balanceada\n",
    "\n",
    "Después de estas validaciones iniciales, se modifican los nombres de las variables\n",
    "para su interpretabilidad y se realiza un Análisis de Datos Exploratorio para conocer\n",
    "mejor el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datos.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Verificación de datos nulos en el dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Para variables categoricas y binarias, verificación de que no hayan elementos mal escritos o similar.\n",
    "# Para esto, se imprimen los valores únicos de cada variable\n",
    "variables_bin_cat = [\n",
    "    \"Work_accident\",\n",
    "    \"left\",\n",
    "    \"promotion_last_5years\",\n",
    "    \"sales\",\n",
    "    \"salary\",\n",
    "]\n",
    "[(i, df[i].unique(), len(df[i].unique())) for i in variables_bin_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df[\"sales\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(df.drop(\"salary\", axis=1))\n",
    "y = df[\"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = RandomForestClassifier()\n",
    "modelo.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(modelo.predict(x) == y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Para la verificación de variables númericas continuas, se usa DataFrame.describe() para validar el rango de los datos\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Se renombra \"sales\" como \"department\", \"salary\" como \"salary_level\", \"left\" como \"employee_left\"\n",
    "# Esto es para dar nombres más interpretables de las variables\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"sales\": \"department\",\n",
    "        \"salary\": \"salary_level\",\n",
    "        \"left\": \"employee_left\",\n",
    "        \"average_montly_hours\": \"average_monthly_hours\",\n",
    "    }\n",
    ")\n",
    "# Se convierten las variables a tipo Categoría para facilitar el uso de modelos\n",
    "df = df.astype({\"department\": \"category\", \"salary_level\": \"category\"})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Se verifica si la variable respuesta se encuentra balanceada en el dataset, mostrando el conteo de la misma\n",
    "df.groupby(\"employee_left\")[\"department\"].count().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Se realiza un mapa de calor de Predictive Power Score (PPS).\n",
    "# El PPS es una métrica que mide el poder predictivo de una variable sobre otra.\n",
    "# Esta se utiliza para observar correlaciones y posibles variables de interés para los modelos\n",
    "matrix_df = pps.matrix(df)[[\"x\", \"y\", \"ppscore\"]].pivot(\n",
    "    columns=\"x\", index=\"y\", values=\"ppscore\"\n",
    ")\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.heatmap(matrix_df, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.5, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_X_y(df, y_name):\n",
    "    \"\"\" \"\"\"\n",
    "    y = [y_name]\n",
    "    X = [col for col in df.columns if col not in y]\n",
    "    y = df[y].copy().values.flatten()\n",
    "    X = pd.get_dummies(df[X].copy())\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def data_preprocessing_up_or_down_sample(X, y, sample=\"up\", test_size=0.2):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    # Use the sample parameter to define local variables to select the correct\n",
    "    # method\n",
    "    a, b = 0, 0\n",
    "    if sample == \"up\":\n",
    "        a, b = 1, 0\n",
    "    if sample == \"down\":\n",
    "        a, b = 0, 1\n",
    "\n",
    "    # Apply the normal train_test_split to the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    # Using the a and b local variables, apply downsampling or upsampling only\n",
    "    # if the sample parameter is \"up\" or \"down\".\n",
    "\n",
    "    if a + b >= 1:\n",
    "        X_train_temp, y_train_temp = resample(\n",
    "            X_train[y_train == a],\n",
    "            y_train[y_train == a],\n",
    "            n_samples=X_train[y_train == b].shape[0],\n",
    "        )\n",
    "        X_train = np.concatenate((X_train[y_train == b], X_train_temp))\n",
    "        y_train = np.concatenate((y_train[y_train == b], y_train_temp))\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "def plot_roc_conf_matrix(y_test, X_test, model, model_name):\n",
    "    \"\"\" \"\"\"\n",
    "    try:\n",
    "        y_pred = model.predict_classes(X_test)\n",
    "    except:\n",
    "        y_pred = model.predict(X_test)\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"g\", cmap=\"Blues\")\n",
    "    plt.title(model_name + \" - Matriz de confusión\", y=1.1, fontdict={\"fontsize\": 21})\n",
    "    plt.xlabel(\"Predicted\", fontdict={\"fontsize\": 14})\n",
    "    plt.ylabel(\"Actual\", fontdict={\"fontsize\": 14})\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    rocauc_plot(model, model_name, y_test, X_test)\n",
    "\n",
    "\n",
    "def rocauc_plot(model, model_name, y_test, X_test):\n",
    "    \"\"\" \"\"\"\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    except:\n",
    "        auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, model.predict(X_test))\n",
    "    plt.plot(fpr, tpr, label=model_name + \" AUC = {:.5f}\".format(auc))\n",
    "    plt.title(\"Curva(s) ROC\", fontdict={\"fontsize\": 21})\n",
    "    plt.xlabel(\"False positive rate\", fontdict={\"fontsize\": 13})\n",
    "    plt.ylabel(\"True positive rate\", fontdict={\"fontsize\": 13})\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.plot([0, 1], [0, 1], \"r--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"employee_left\", \"number_project\", \"satisfaction_level\", \"salary_level\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, y = get_X_y(\n",
    "    df[\n",
    "        [\"employee_left\", \"average_monthly_hours\", \"satisfaction_level\", \"salary_level\"]\n",
    "    ],\n",
    "    \"employee_left\",\n",
    ")\n",
    "X_train, X_test, y_train, y_test = data_preprocessing_up_or_down_sample(\n",
    "    X, y, \"up\", test_size=0.2\n",
    ")\n",
    "X_train = pd.DataFrame(columns=X.columns, data=X_train)\n",
    "for columna in [\n",
    "    \"average_monthly_hours\",\n",
    "    \"salary_level_high\",\n",
    "    \"salary_level_low\",\n",
    "    \"salary_level_medium\",\n",
    "]:\n",
    "    X_train[columna] = X_train[columna].astype(int)\n",
    "\n",
    "param_grid = {\n",
    "    \"randomforestclassifier__min_samples_leaf\": np.arange(1, 11, 2),\n",
    "    \"randomforestclassifier__n_estimators\": np.arange(100, 1000 + 100, 250),\n",
    "    \"randomforestclassifier__criterion\": [\"gini\", \"entropy\"],\n",
    "}\n",
    "pipe = make_pipeline(StandardScaler(), RandomForestClassifier(class_weight=\"balanced\"))\n",
    "clf = GridSearchCV(\n",
    "    pipe, param_grid=param_grid, cv=5, refit=True, scoring=\"f1\", n_jobs=-1\n",
    ")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_roc_conf_matrix(y_test, X_test, clf, \"Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# SE GUARDA EL MODELO\n",
    "joblib.dump(clf, \"model ex.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 1: Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel as BM\n",
    "from pydantic import Field\n",
    "from typing import Literal\n",
    "from pydantic import ValidationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputModeloNo:\n",
    "    def __init__(self, salary_level: str):\n",
    "        if isinstance(salary_level, str):\n",
    "            if salary_level in [\"low\", \"medium\", \"high\"]:\n",
    "                self.salary_level = salary_level\n",
    "                print(\":)\")\n",
    "            else:\n",
    "                print(\":'(\")\n",
    "        else:\n",
    "            print(\":'(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputModeloNo(salary_level=\"low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputModelo(BM):\n",
    "    \"\"\"\n",
    "    Clase que define las entradas del modelo según las verá el usuario.\n",
    "    \"\"\"\n",
    "\n",
    "    average_monthly_hours: int = Field(\n",
    "        ge=96, le=310, description=\"Horas promedio mensuales trabajadas\"\n",
    "    )\n",
    "    satisfaction_level: float = Field(ge=0, le=1)\n",
    "    salary_level: Literal[\"high\", \"low\", \"medium\"]\n",
    "\n",
    "    class Config:\n",
    "        scheme_extra = {\n",
    "            \"example\": {\n",
    "                \"average_monthly_hours\": 201,\n",
    "                \"satisfaction_level\": 0.42,\n",
    "                \"salay_level\": \"high\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class OutputModelo(BM):\n",
    "    \"\"\"\n",
    "    Clase que define la salida del modelo según la verá el usuario.\n",
    "    \"\"\"\n",
    "\n",
    "    employee_left: float = Field(ge=0, le=1)\n",
    "\n",
    "    class Config:\n",
    "        scheme_extra = {\n",
    "            \"example\": {\n",
    "                \"employee_left\": 0.69,\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "clf = joblib.load(\"model ex.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_monthly_hours = 201\n",
    "satisfaction_level = 0\n",
    "salary_level = \"high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputModelo(\n",
    "    average_monthly_hours=average_monthly_hours,\n",
    "    satisfaction_level=satisfaction_level,\n",
    "    salary_level=salary_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputModelo(\n",
    "    average_monthly_hours=average_monthly_hours,\n",
    "    satisfaction_level=satisfaction_level,\n",
    "    salary_level=salary_level,\n",
    ")\n",
    "\n",
    "salary_levels = [0] * 3\n",
    "\n",
    "# Crea el DataFrame en el mismo orden las columnas del X_train\n",
    "\n",
    "data_predict = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"average_monthly_hours\",\n",
    "        \"satisfaction_level\",\n",
    "        \"salary_level_high\",\n",
    "        \"salary_level_low\",\n",
    "        \"salary_level_medium\",\n",
    "    ],\n",
    "    data=[[average_monthly_hours, satisfaction_level, *salary_levels]],\n",
    ")\n",
    "\n",
    "# Pone el 1 en la columna que debe ir el 1\n",
    "\n",
    "data_predict[\n",
    "    [\n",
    "        x\n",
    "        for x in data_predict.columns\n",
    "        if ((salary_level in x) and (x.startswith(\"salary_level_\")))\n",
    "    ]\n",
    "] = 1\n",
    "\n",
    "\n",
    "pd.DataFrame(clf.predict_proba(data_predict)[:, 1]).rename(columns={0: \"prediccion\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(clf.predict_proba(data_predict)[:, 1]).rename(columns={0: \"prediccion\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 2: FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se carga el modelo\n",
    "\n",
    "import joblib\n",
    "\n",
    "first_model = joblib.load(\"model ex.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos un archivo llamado classes.py para guardar todo lo que hacemos con las clases\n",
    "\n",
    "De la sesión pasada, tenmos parte del archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel as BM\n",
    "from pydantic import Field\n",
    "from typing import Literal\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "\n",
    "class InputModelo(BM):\n",
    "    \"\"\"\n",
    "    Clase que define las entradas del modelo según las verá el usuario.\n",
    "    \"\"\"\n",
    "\n",
    "    average_monthly_hours: int = Field(\n",
    "        ge=96, le=310, description=\"Horas promedio mensuales trabajadas\"\n",
    "    )\n",
    "    satisfaction_level: float = Field(ge=0, le=1)\n",
    "    salary_level: Literal[\"high\", \"low\", \"medium\"]\n",
    "\n",
    "    class Config:\n",
    "        scheme_extra = {\n",
    "            \"example\": {\n",
    "                \"average_monthly_hours\": 201,\n",
    "                \"satisfaction_level\": 0.42,\n",
    "                \"salay_level\": \"high\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class OutputModelo(BM):\n",
    "    \"\"\"\n",
    "    Clase que define la salida del modelo según la verá el usuario.\n",
    "    \"\"\"\n",
    "\n",
    "    employee_left: float = Field(ge=0, le=1)\n",
    "\n",
    "    class Config:\n",
    "        scheme_extra = {\n",
    "            \"example\": {\n",
    "                \"employee_left\": 0.69,\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class APIModelBackEnd:\n",
    "    def __init__(self, average_monthly_hours, satisfaction_level, salary_level):\n",
    "\n",
    "        self.average_monthly_hours = average_monthly_hours\n",
    "        self.satisfaction_level = satisfaction_level\n",
    "        self.salary_level = salary_level\n",
    "\n",
    "    def cargar_modelo(self, nombre_modelo: str = \"model ex.pkl\"):\n",
    "        self.model = joblib.load(nombre_modelo)\n",
    "\n",
    "    def preparar_datos_modelo(self):\n",
    "\n",
    "        average_monthly_hours = self.average_monthly_hours\n",
    "        satisfaction_level = self.satisfaction_level\n",
    "        salary_level = self.salary_level\n",
    "\n",
    "        salary_levels = [0] * 3\n",
    "\n",
    "        # Crea el DataFrame en el mismo orden las columnas del X_train\n",
    "\n",
    "        data_predict = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"average_monthly_hours\",\n",
    "                \"satisfaction_level\",\n",
    "                \"salary_level_high\",\n",
    "                \"salary_level_low\",\n",
    "                \"salary_level_medium\",\n",
    "            ],\n",
    "            data=[[average_monthly_hours, satisfaction_level, *salary_levels]],\n",
    "        )\n",
    "\n",
    "        # Pone el 1 en la columna que debe ir el 1\n",
    "\n",
    "        data_predict[\n",
    "            [\n",
    "                x\n",
    "                for x in data_predict.columns\n",
    "                if ((salary_level in x) and (x.startswith(\"salary_level_\")))\n",
    "            ]\n",
    "        ] = 1\n",
    "\n",
    "        return data_predict\n",
    "\n",
    "    def predecir(self):\n",
    "        self.cargar_modelo()\n",
    "        x = self.preparar_datos_modelo()\n",
    "        prediccion = pd.DataFrame(self.model.predict_proba(x)[:, 1]).rename(\n",
    "            columns={0: \"employee_left\"}\n",
    "        )\n",
    "\n",
    "        return prediccion.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_class = APIModelBackEnd(\n",
    "    average_monthly_hours=average_monthly_hours,\n",
    "    satisfaction_level=satisfaction_level,\n",
    "    salary_level=salary_level,\n",
    ")\n",
    "first_class.predecir()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from typing import List\n",
    "\n",
    "app = FastAPI(title=\"Mi  API de ML\", version=\"1.0.1\")\n",
    "\n",
    "\n",
    "@app.post(\"/predict\", response_model=List[OutputModelo])\n",
    "def predecir_probabilidad(inputs: List[InputModelo]):\n",
    "    respuestas = list()\n",
    "    for Input in inputs:\n",
    "        first_model = APIModelBackEnd(\n",
    "            Input.average_monthly_hours, Input.satisfaction_level, Input.salary_level\n",
    "        )\n",
    "\n",
    "        respuestas.append(first_model.predecir()[0])\n",
    "\n",
    "    return respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_montly_hours = 201\n",
    "satisfaction_level = 0\n",
    "salary_level = \"low\"\n",
    "test = APIModelBackEnd(\n",
    "    average_montly_hours=average_montly_hours,\n",
    "    satisfaction_level=satisfaction_level,\n",
    "    salary_level=salary_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutputModelo(employee_left=test.predecir()[0][\"employee_left\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "average_monthly_hours = 300\n",
    "satisfaction_level = 0.12\n",
    "salary_level = \"medium\"\n",
    "\n",
    "request_data = [\n",
    "    {\n",
    "        \"average_monthly_hours\": average_monthly_hours,\n",
    "        \"satisfaction_level\": satisfaction_level,\n",
    "        \"salary_level\": salary_level,\n",
    "    }\n",
    "]\n",
    "\n",
    "data_cleaned = str(request_data).replace(\"'\", '\"')\n",
    "\n",
    "url_api = \"https://api-diplomadopython.herokuapp.com/predict\"\n",
    "\n",
    "pred = requests.post(url=url_api, data=data_cleaned).text\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Clase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leemos los datos de la fuente\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = df[df[\"Country/Region\"].apply(lambda x: x in [\"Colombia\"])].copy()\n",
    "df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = df_col.melt(\n",
    "    var_name=\"Fechas\",\n",
    "    value_name=\"confirmados\",\n",
    "    id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"],\n",
    ")\n",
    "melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "melted[\"Fechas\"] = melted[\"Fechas\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%m/%d/%y\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dibujar_serie_tiempo(\n",
    "    data, x=\"Fechas\", y=\"confirmados\", title=\"Casos de COVID Confirmados en Colombia\"\n",
    "):\n",
    "    fig = px.line(\n",
    "        data,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        title=title,\n",
    "        color_discrete_sequence=[\"red\", \"blue\"],\n",
    "    )\n",
    "\n",
    "    fig.update_layout(yaxis_title=\"Casos confirmados\", xaxis_title=\"Fecha\")\n",
    "    # Esto elimina el color del fondo:\n",
    "    fig.update_layout(\n",
    "        {\"plot_bgcolor\": \"rgba(0,0,0,0)\", \"paper_bgcolor\": \"rgba(0,0,0,0)\"}\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        rangeslider_visible=True,\n",
    "        rangeselector=dict(\n",
    "            buttons=list(\n",
    "                [\n",
    "                    dict(step=\"day\", stepmode=\"backward\", label=\"1 semana\", count=7),\n",
    "                    dict(step=\"month\", stepmode=\"backward\", label=\"1 mes\", count=1),\n",
    "                    dict(step=\"month\", stepmode=\"backward\", label=\"3 meses\", count=3),\n",
    "                    dict(step=\"month\", stepmode=\"backward\", label=\"6 meses\", count=6),\n",
    "                    dict(label=\"Todos\", step=\"all\"),\n",
    "                ]\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        hovertemplate=\"<b><i>\"\n",
    "        + \"Casos confirmados\"\n",
    "        + \"</i></b>: %{y} <br><b><i>\"\n",
    "        + \"Fecha\"\n",
    "        + \"</i></b>: %{x} <extra></extra>\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "# fig.update_xaxes(dtick='M1', ticklabelmode='period', tickformat=\"%d %b\\n%Y\")\n",
    "\n",
    "fig = dibujar_serie_tiempo(melted)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.update_xaxes(\n",
    "    rangeslider_visible=True,\n",
    "    rangeselector=dict(\n",
    "        buttons=list(\n",
    "            [\n",
    "                dict(step=\"day\", stepmode=\"backward\", label=\"1 semana\", count=7),\n",
    "                dict(step=\"month\", stepmode=\"backward\", label=\"1 mes\", count=1),\n",
    "                dict(step=\"month\", stepmode=\"backward\", label=\"3 meses\", count=3),\n",
    "                dict(step=\"month\", stepmode=\"backward\", label=\"6 meses\", count=6),\n",
    "                dict(label=\"Todos\", step=\"all\"),\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(df: pd.DataFrame, x: str, y: str):\n",
    "    data_heatmap = (\n",
    "        df.reset_index()[[x, y, \"index\"]]\n",
    "        .groupby([x, y])\n",
    "        .count()\n",
    "        .reset_index()\n",
    "        .pivot(x, y, \"index\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "    fig = px.imshow(\n",
    "        data_heatmap,\n",
    "        color_continuous_scale=\"Reds\",\n",
    "        aspect=\"auto\",\n",
    "        title=f\"Heatmap {x} vs {y}\",\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        hovertemplate=\"<b><i>\"\n",
    "        + y\n",
    "        + \"</i></b>: %{y} <br><b><i>\"\n",
    "        + x\n",
    "        + \"</i></b>: %{x} <br><b><i>Conteo interacción variables</i></b>: %{z}<extra></extra>\"\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"datos.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(df2, x=\"sales\", y=\"salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(\"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(\"5\", str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set([1])\n",
    "b = set([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "any(a.intersection(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "1 in [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 == \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 == 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in \"hola\":\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate([3, 2, 1, 0]):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate(\"holi\"):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {0: 1, 1: 1, 2: 1}:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion(holi: str = \"d\"):\n",
    "    t = 1 == 2 | 9 == 9 | 1 == 3\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejemplo(txt:str):\n",
    "    return txt + 'Hola'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ejemplo(txt:str):\n",
    "    assert \"holaHola\"==ejemplo(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ejemplo(\"hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(columns=['Hola'], data= [['aihdaio'], ['92487932ada']])['Hola'].apply(lambda x: str(x).upper()).apply(lambda x: re.sub(\"[9]\", \"holi\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(columns=[\"Hola\"], data=[[\"aihdaio\"], [\"92487932ada\"]])[\"Hola\"].apply(\n",
    "    lambda x: str(x).upper()\n",
    ").apply(lambda x: re.sub(\"[9]\", \"holi\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(columns=[\"Hola\"], data=[[\"aihdaio\"], [\"92487932ada\"]])[\"Hola\"].apply(\n",
    "    lambda x: str(x).upper()\n",
    ").apply(\n",
    "    lambda x: re.sub(\"[9]\", \"holi\", x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.DataFrame(columns=[\"Hola\"], data=[[\"aihdaio\"], [\"92487932ada\"]])[\"Hola\"]\n",
    "    .apply(lambda x: str(x).upper())\n",
    "    .apply(lambda x: re.sub(\"[9]\", \"holi\", x))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config, UndefinedValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deben crear un archivo '.env' con:\n",
    "\n",
    "'''\n",
    "EJEMPLO = \"Acá en comillas ponen el valor que quieren darle a la variable\"\n",
    "'''\n",
    "config(\"EJEMPLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sesion iniciada\n"
     ]
    }
   ],
   "source": [
    "def login(usuario, contraseña):\n",
    "    \"\"\"\n",
    "    ESTO ES UN EJEMPLO DE LO QUE QUEREMOS EVITAR QUE QUEDE USANDO VARIABLES DE ENTORNO\n",
    "\n",
    "    NO USAR\n",
    "    NO COPIAR Y PEGAR\n",
    "\n",
    "\n",
    "    NO USAR\n",
    "    \"\"\"\n",
    "\n",
    "    # ESTO ES UN PECADO CAPITAL\n",
    "    if (usuario == \"user\") and (contraseña == \"password\"):\n",
    "        print(\"sesion iniciada\")\n",
    "    else:\n",
    "        print(\"datos invalidos\")\n",
    "\n",
    "\n",
    "login(\"user\", \"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ejemplo = config(\"EJEMPLO\")\n",
    "    \n",
    "except UndefinedValueError:\n",
    "    ejemplo = 'ERROR'\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "except ModuleNotFoundError:\n",
    "    !pip install pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
